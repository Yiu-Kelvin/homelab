apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: rook-ceph
  namespace: storage
spec:
  cephVersion:
    image: quay.io/ceph/ceph:v18.2.2         # Ceph "Reef" example (adjust as needed)
    allowUnsupported: false
  dataDirHostPath: /var/lib/rook             # Where Rook stores metadata on nodes
  # Use host networking cautiously. Often false is fine; true helps in restricted CNI setups.
  network:
    hostNetwork: false
    # You can also segregate cluster/public networks via 'provider' (e.g., 'host') + 'selectors'
    # provider: host
    # selectors:
    #   public: "node-role.kubernetes.io/storage="
    #   cluster: "node-role.kubernetes.io/storage="
  mon:
    count: 3                                 # MONs: 3 for HA (avoid even numbers)
    allowMultiplePerNode: false
  mgr:
    count: 1                                 # MGR count (Ceph will handle standby internally)
  dashboard:
    enabled: true                            # Ceph Dashboard
    # ssl: true
  # Resources/priority classes are recommended in prod; keep omitted for brevity.
  # resources:
  # priorityClassName: system-cluster-critical

  # Storage: configure OSDs
  storage:
    useAllNodes: true                        # Use all schedulable nodes (or label-select)
    useAllDevices: false                     # false: only consume devices you list below
    devices:                                 # Explicit device list per node via MachineDisruptionBudget or node selector is better
      - name: "/dev/datavg/data"                      # Example device name (adjust per node)
      - name: "sdb"

    # Alternatively, enable the device discovery operator:
    # deviceFilter: "^sd[b-z]$"               # Regex filter
  healthCheck:
    daemonHealth:
      mon:
        interval: 45s
        timeout: 600s
      osd:
        interval: 60s
        timeout: 600s
      status:
        interval: 60s

  # Crash collector helps with automated crash reports into Ceph
  crashCollector:
    disable: false

---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rook-ceph-block
provisioner: rook-ceph.rbd.csi.ceph.com
parameters:
  clusterID: rook-ceph  # Must match your CephCluster namespace
  pool: replicapool
  imageFormat: "2"
  imageFeatures: layering
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate

